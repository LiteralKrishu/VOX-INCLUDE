# VOX-INCLUDE

<div align="center">

**Voice-Oriented eXpressive INterpretation for Communication, Learning & Universal Design Ecosystems**

*An emotion-aware, intent-interpreting voice intelligence platform for universal understanding.*

[![Python 3.10+](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![Flutter](https://img.shields.io/badge/Flutter-3.x-02569B.svg)](https://flutter.dev/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-009688.svg)](https://fastapi.tiangolo.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

</div>

---

## ğŸ“Œ Vision

VOX-INCLUDE translates human speech into **emotionally contextualized, visually adaptive communication outputs**. It reframes accessibility as intelligent system adaptation rather than user accommodation. The system evaluates *understanding* and adapts accordinglyâ€”not people.

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           VOX-INCLUDE ARCHITECTURE                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Voice     â”‚â”€â”€â”€â–¶â”‚   Feature   â”‚â”€â”€â”€â–¶â”‚   Emotion   â”‚â”€â”€â”€â–¶â”‚  Cognitive  â”‚  â”‚
â”‚  â”‚   Input     â”‚    â”‚  Extractor  â”‚    â”‚ Recognizer  â”‚    â”‚  Estimator  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                   â”‚         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚         â”‚
â”‚  â”‚   Text/     â”‚â”€â”€â”€â–¶â”‚   Intent    â”‚â”€â”€â”€â–¶â”‚   Memory    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚  â”‚   STT       â”‚    â”‚ Classifier  â”‚    â”‚   Graph     â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                                                   â”‚         â”‚
â”‚                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚                           â”‚        INTERVENTION ENGINE                    â”‚ â”‚
â”‚                           â”‚   â€¢ Rising Confusion â†’ Simplify               â”‚ â”‚
â”‚                           â”‚   â€¢ Cognitive Fatigue â†’ Micro-breaks          â”‚ â”‚
â”‚                           â”‚   â€¢ Social Anxiety â†’ Private channels         â”‚ â”‚
â”‚                           â”‚   â€¢ High Engagement â†’ Increase challenge      â”‚ â”‚
â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                              â”‚                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                      ADAPTIVE OUTPUT GENERATOR                         â”‚ â”‚
â”‚  â”‚   â€¢ Dynamic Meaning Ribbons  â€¢ Emotion Gradients  â€¢ Accessibility     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                         PRIVACY LAYER                                 â”‚  â”‚
â”‚  â”‚  Consent Manager â”‚ Anonymization â”‚ Explainability â”‚ Data Minimization â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
VOX-INCLUDE/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ audio_processing/       # Feature extraction (MFCC, prosody, SNR)
â”‚   â”‚   â”œâ”€â”€ feature_extraction.py
â”‚   â”‚   â””â”€â”€ audio_capture.py
â”‚   â”‚
â”‚   â”œâ”€â”€ emotion_recognition/    # Speech Emotion Recognition
â”‚   â”‚   â”œâ”€â”€ models.py           # EmotionRecognizer (Wav2Vec2)
â”‚   â”‚   â”‚                       # SimplisticEmotionRecognizer (rule-based)
â”‚   â”‚   â””â”€â”€ trajectory.py       # Emotion momentum & trends
â”‚   â”‚
â”‚   â”œâ”€â”€ intent_recognition/     # Intent & Cognitive State
â”‚   â”‚   â”œâ”€â”€ intent_classifier.py    # Rule + Transformer classification
â”‚   â”‚   â”œâ”€â”€ memory_graph.py         # Conversational memory
â”‚   â”‚   â””â”€â”€ cognitive_estimator.py  # Bayesian state estimation
â”‚   â”‚
â”‚   â”œâ”€â”€ adaptive_system/        # Closed-Loop Interventions
â”‚   â”‚   â”œâ”€â”€ intervention_engine.py  # Stateâ†’Action mapping
â”‚   â”‚   â””â”€â”€ output_generator.py     # Content adaptation
â”‚   â”‚
â”‚   â”œâ”€â”€ privacy/                # Ethical Architecture
â”‚   â”‚   â”œâ”€â”€ anonymization.py    # Differential privacy, secure deletion
â”‚   â”‚   â””â”€â”€ consent_manager.py  # Permissions, audit, transparency
â”‚   â”‚
â”‚   â”œâ”€â”€ edge/                   # Edge Deployment
â”‚   â”‚   â”œâ”€â”€ tflite_converter.py     # Model optimization
â”‚   â”‚   â””â”€â”€ offline_inference.py    # Offline + cultural profiles
â”‚   â”‚
â”‚   â”œâ”€â”€ api/                    # FastAPI Backend
â”‚   â”‚   â”œâ”€â”€ main.py             # All REST endpoints
â”‚   â”‚   â””â”€â”€ security.py         # Auth, rate limiting
â”‚   â”‚
â”‚   â””â”€â”€ utils/                  # Shared utilities
â”‚       â””â”€â”€ config.py           # Configuration loader
â”‚
â”œâ”€â”€ mobile_app/                 # Flutter Application
â”‚   â””â”€â”€ lib/
â”‚       â”œâ”€â”€ main.dart                 # App entry point
â”‚       â””â”€â”€ src/
â”‚           â”œâ”€â”€ app.dart              # MaterialApp with adaptive routing
â”‚           â”œâ”€â”€ core/
â”‚           â”‚   â”œâ”€â”€ api/              # API client (Dio)
â”‚           â”‚   â””â”€â”€ theme/            # AppColors, accessibility provider
â”‚           â””â”€â”€ features/
â”‚               â”œâ”€â”€ analysis/
â”‚               â”‚   â”œâ”€â”€ data/         # AnalysisRepository
â”‚               â”‚   â”œâ”€â”€ domain/       # Models (AnalysisResult, Emotion, etc.)
â”‚               â”‚   â””â”€â”€ presentation/
â”‚               â”‚       â”œâ”€â”€ analysis_controller.dart  # Riverpod state
â”‚               â”‚       â”œâ”€â”€ dashboard_screen.dart     # Mobile/Web UI
â”‚               â”‚       â””â”€â”€ watch_dashboard_screen.dart  # Wear OS UI
â”‚               â”œâ”€â”€ audio/
â”‚               â”‚   â””â”€â”€ data/
â”‚               â”‚       â”œâ”€â”€ audio_recorder_service.dart   # Recording
â”‚               â”‚       â””â”€â”€ transcription_service.dart    # Speech-to-text
â”‚               â””â”€â”€ intervention/
â”‚                   â””â”€â”€ presentation/
â”‚                       â””â”€â”€ meaning_ribbon.dart  # Transcript display
â”‚
â”œâ”€â”€ tests/                      # Test Suite
â”‚   â”œâ”€â”€ test_integration.py     # Full pipeline tests
â”‚   â”œâ”€â”€ test_phase7_privacy.py  # Privacy tests (12 passing)
â”‚   â”œâ”€â”€ test_phase8_edge.py     # Edge tests (20 passing)
â”‚   â””â”€â”€ uat_framework.py        # User acceptance testing
â”‚
â”œâ”€â”€ models/                     # Pre-trained models & TFLite
â”œâ”€â”€ config.yaml                 # Application configuration
â””â”€â”€ requirements.txt            # Python dependencies
```

---

## ğŸš€ Quick Start

### Backend (Python)

```bash
# Create virtual environment
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt

# Run the API server
python -m src.api.main
```

API available at: `http://localhost:8000`
- Swagger docs: `http://localhost:8000/docs`

### Flutter App (Mobile/Web/Watch)

```bash
cd mobile_app

# Install dependencies
flutter pub get

# Run on connected device
flutter run

# Run on web
flutter run -d chrome

# Run on specific device
flutter devices  # List available devices
flutter run -d <device_id>
```

### Build Commands

```bash
# Android APK
flutter build apk

# Android App Bundle
flutter build appbundle

# iOS
flutter build ios

# Web
flutter build web

# Wear OS (uses same Android build)
flutter build apk --target-platform android-arm64
```

### Development Script (Windows)

```powershell
# Start both backend and Flutter simultaneously
.\run_dev.ps1
```

---

## ğŸ”Œ API Endpoints

### Core Analysis

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/analyze` | POST | Full emotion + features analysis |
| `/api/v1/comprehensive` | POST | Complete pipeline (emotion, intent, cognitive, intervention) |
| `/api/v1/emotion` | POST | Emotion recognition only |
| `/api/v1/intent` | POST | Intent classification from text |
| `/api/v1/cognitive-state` | POST | Cognitive state estimation |
| `/api/v1/intervention` | POST | Get intervention recommendations |

### Privacy & Consent

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/privacy/consent` | POST | Update consent settings |
| `/api/v1/privacy/consent/{user}/{session}` | GET | Get consent status |
| `/api/v1/privacy/export/{user}/{session}` | GET | Export user data (GDPR) |
| `/api/v1/privacy/delete/{user}/{session}` | DELETE | Right to be forgotten |
| `/api/v1/privacy/explain` | POST | Explainable AI decision |
| `/api/v1/privacy/transparency/{user}/{session}` | GET | Processing summary |

### Utilities

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/health` | GET | Health check |
| `/api/v1/features` | POST | Extract audio features |
| `/api/v1/conversation/context` | GET | Get conversation context |
| `/api/v1/conversation/clear` | POST | Clear session history |

---

## ğŸ¯ Feature Comparison vs Reference Vision

| Reference Vision | Implementation Status | Details |
|-----------------|----------------------|---------|
| **Advanced SER (Bi-LSTM)** | âœ… Implemented | Wav2Vec2 + SimplisticEmotionRecognizer fallback |
| **Temporal Emotion Processing** | âœ… Implemented | Momentum, trends, decay tracking |
| **Cross-Cultural Calibration** | âœ… Implemented | 6 cultural profiles in CulturalAdaptability |
| **Cognitive State Estimation** | âœ… Implemented | Overload, engagement, anxiety, confusion |
| **Conversational Memory Graph** | âœ… Implemented | Topic tracking, unresolved questions |
| **Bayesian Confidence** | âœ… Implemented | Fusion with calibrated uncertainty |
| **Closed-Loop Interventions** | âœ… Implemented | 5 intervention types with actions |
| **Visual Language System** | âœ… Implemented | Meaning ribbons, emotion gradients |
| **Adaptive Accessibility** | âœ… Implemented | Hearing, neurodiverse, standard modes |
| **On-Device Processing** | âœ… Implemented | TFLite converter, offline inference |
| **Granular Consent** | âœ… Implemented | 4 permission levels, opaque mode |
| **Explainable AI** | âœ… Implemented | TransparencyDashboard with factors |
| **Data Minimization** | âœ… Implemented | Secure deletion, differential privacy |
| **Flutter Visualization** | âœ… Implemented | Mobile, Web, and Wear OS support |
| **API Ecosystem** | âœ… Implemented | FastAPI with auth & rate limiting |

---

## ğŸ§  Cognitive States Detected

| State | Detected From | System Response |
|-------|---------------|-----------------|
| **Cognitive Overload** | Fast speech + confusion + repetition | Auto-simplify content |
| **Productive Struggle** | Confusion + high engagement | Encourage, provide hints |
| **Passive Disengagement** | Low energy + long pauses | Re-engage, suggest break |
| **Social Anxiety** | Low volume + hesitation | Private channels, reduce spotlight |
| **High Engagement** | Positive emotion + focused intent | Increase challenge depth |

---

## ğŸ” Privacy Features

### Permission Levels

| Level | Allowed Data |
|-------|-------------|
| **NONE** | No processing |
| **VOICE_ONLY** | Audio, transcript, emotion, intent |
| **VOICE_BEHAVIORAL** | + Interaction patterns |
| **FULL_MULTIMODAL** | + Facial (if implemented) |

### Privacy Controls

- **Differential Privacy**: Calibrated noise added to aggregate features
- **Secure Deletion**: Memory buffers overwritten after processing
- **PII Redaction**: Email, phone, card numbers automatically redacted
- **Audit Logging**: All data access is logged
- **Right to Opaqueness**: Receive benefits without detailed analysis
- **GDPR Export**: Full data export capability
- **Right to be Forgotten**: Complete data deletion

---

## ğŸŒ Cultural Adaptability

| Profile | Expression Intensity | Interpretation Adjustments |
|---------|---------------------|---------------------------|
| Western | 1.0 | Direct communication baseline |
| Eastern Asian | 0.6 | Boost subtle expression confidence |
| South Asian | 0.9 | Moderate expression adjustment |
| Middle Eastern | 0.95 | High expression baseline |
| Latin | 1.1 | Expressive baseline |
| Neutral | 1.0 | No adjustments |

---

## ğŸ“Š Performance Targets

| Component | Target | Achieved |
|-----------|--------|----------|
| Feature Extraction | <100ms | âœ… ~50ms avg |
| Emotion Recognition | <100ms | âœ… ~20ms (SimplisticEmotionRecognizer) |
| Intent Classification | <50ms | âœ… ~10ms (rule-based) |
| Full Pipeline | <500ms | âœ… ~200ms avg |

---

## ğŸ§ª Test Suite

```bash
# Run all tests
python -m pytest tests/ -v

# Specific test modules
python -m pytest tests/test_phase7_privacy.py -v  # 12 tests
python -m pytest tests/test_phase8_edge.py -v     # 20 tests
python -m pytest tests/test_integration.py -v     # Integration tests
```

---

## ğŸ“± Flutter App

### Platforms Supported
- âœ… Android (Mobile)
- âœ… iOS (Mobile)
- âœ… Web (Chrome/Firefox)
- âœ… Wear OS (Smart Watch)

### Key Features

| Feature | Description |
|---------|-------------|
| **Adaptive UI** | Auto-detects watch vs phone/tablet screen size |
| **Real-time Analysis** | Live audio â†’ API â†’ emotion/intent display |
| **Transcript Visualization** | Emotion-colored real-time transcript |
| **API Status Indicator** | Recording/Processing/Done states |
| **Live Metrics Panel** | Confidence, arousal, valence, momentum |

### Accessibility Modes

| Mode | Features |
|------|----------|
| **Standard** | Full visualization with emotion gradients |
| **Hearing Impaired** | Large text, explicit visual indicators |
| **Neurodiverse** | Reduced motion, calmer colors, structured layout |

### Watch Dashboard (Wear OS)
- Simplified single-button interface
- High-contrast colors
- Status ring around main button
- Ambient mode support

### Flutter Dependencies
- `flutter_riverpod` - State management
- `dio` - HTTP client
- `record` - Audio recording
- `speech_to_text` - Transcription
- `wear` - Wear OS support

### API Configuration

Edit `mobile_app/lib/src/core/api/api_client.dart`:

```dart
BaseOptions(
  baseUrl: 'http://YOUR_SERVER_IP:8000',
  connectTimeout: Duration(seconds: 10),
  receiveTimeout: Duration(seconds: 30),
)
```

> For physical device testing, use your machine's local IP (not localhost).

---

## ğŸ› ï¸ Configuration

Edit `config.yaml`:

```yaml
audio:
  sample_rate: 16000
  channels: 1
  chunk_size: 1024

features:
  mfcc_coefficients: 40
  n_fft: 2048
  hop_length: 512

model:
  emotion_model: "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition"
  confidence_threshold: 0.5

api:
  host: "0.0.0.0"
  port: 8000
  cors_origins: ["*"]
```

---

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

VOX-INCLUDE represents the evolution of assistive technologyâ€”where AI doesn't just accommodate differences but actively collaborates to create understanding.

> *"Inclusion transforms from a special accommodation into the default mode of human-system interaction."*

---

<div align="center">

**Built with â¤ï¸ for Universal Understanding**

</div>
